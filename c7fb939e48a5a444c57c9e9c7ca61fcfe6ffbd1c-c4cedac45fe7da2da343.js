"use strict";(self.webpackChunkmichael_personal_website=self.webpackChunkmichael_personal_website||[]).push([[313],{1046:function(e,n,t){t.d(n,{w_:function(){return l}});var a=t(7294),o={color:void 0,size:void 0,className:void 0,style:void 0,attr:void 0},i=a.createContext&&a.createContext(o),r=function(){return r=Object.assign||function(e){for(var n,t=1,a=arguments.length;t<a;t++)for(var o in n=arguments[t])Object.prototype.hasOwnProperty.call(n,o)&&(e[o]=n[o]);return e},r.apply(this,arguments)},s=function(e,n){var t={};for(var a in e)Object.prototype.hasOwnProperty.call(e,a)&&n.indexOf(a)<0&&(t[a]=e[a]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var o=0;for(a=Object.getOwnPropertySymbols(e);o<a.length;o++)n.indexOf(a[o])<0&&(t[a[o]]=e[a[o]])}return t};function c(e){return e&&e.map((function(e,n){return a.createElement(e.tag,r({key:n},e.attr),c(e.child))}))}function l(e){return function(n){return a.createElement(d,r({attr:r({},e.attr)},n),c(e.child))}}function d(e){var n=function(n){var t,o=e.size||n.size||"1em";n.className&&(t=n.className),e.className&&(t=(t?t+" ":"")+e.className);var i=e.attr,c=e.title,l=s(e,["attr","title"]);return a.createElement("svg",r({stroke:"currentColor",fill:"currentColor",strokeWidth:"0"},n.attr,i,l,{className:t,style:r({color:e.color||n.color},n.style,e.style),height:o,width:o,xmlns:"http://www.w3.org/2000/svg"}),c&&a.createElement("title",null,c),e.children)};return void 0!==i?a.createElement(i.Consumer,null,(function(e){return n(e)})):n(o)}},931:function(e,n,t){t.d(n,{S:function(){return m},E:function(){return p}});var a=t.p+"static/hico-preview-a1690198c87edb588bcf8e25cf6cf219.png",o=t.p+"static/unakite-vlhcc-workshop-6b4cbaf264ce7972331b1e40dd54d0b3.png",i=t.p+"static/stackoverflow-vlhcc-workshop-preview-e43b56ff074bdcdc1edbc215973ba025.jpg",r=t.p+"static/av_anno-d4f3ae94abd63c249624fc4ca9bff54b.png",s=t.p+"static/unakite-uist-2019-2979a6ee4c1d01a61fed4c068b189d6e.png",c=t.p+"static/strata-cscw-2021-8abeb8f798bd549c0dff11b7e4d54ed0.jpg",l=t.p+"static/tabsdo-uist-2021-f954af2f2336f5ac7e66a3f3cc213626.jpg",d=t.p+"static/crystalline-chi-2022-d6e9d10fc342b424705b0d7db3a1d3d3.png",h=t.p+"static/adamite-chi-2022-1b447d3dcec1642a0aeeb92ebc2d988d.png",m=t(5256).I+"/pubs",p={publications:[{title:"Learning to Detect Human-Object Interactions",type:"conference",conference:"WACV",conferenceFullName:"IEEE Winter Conference on Applications of Computer Vision (WACV)",conferenceTag:"WACV 2018",year:2018,month:3,authors:[{name:"Yu-Wei Chao",bold:!1},{name:"Yunfan Liu",bold:!1},{name:"Xieyang Liu",bold:!0},{name:"Huayi Zeng",bold:!1},{name:"Jia Deng",bold:!1}],abstract:"In this paper we study the problem of detecting human-object interactions (HOI) in static images, defined as predicting a human and an object bounding box with an interaction class label that connects them. HOI detection is a fundamental problem in computer vision as it provides semantic information about the interactions among the detected objects. We introduce HICO-DET, a new large benchmark for HOI detection, by augmenting the current HICO classification benchmark with instance annotations. We propose Human-Object Region-based Convolutional Neural Networks (HO-RCNN), a novel DNN-based framework for HOI detection. At the core of our HO-RCNN is the Interaction Pattern, a novel DNN input that characterizes the spatial relations between two bounding boxes. We validate the effectiveness of our HO-RCNN using HICO-DET. Experiments demonstrate that our HO-RCNN, by exploiting human-object spatial relations through Interaction Patterns, significantly improves the performance of HOI detection over baseline approaches. ",codename:"hico",bibtex:"\n  @INPROCEEDINGS{chao:wacv2018,\n    author = {Yu-Wei Chao and Yunfan Liu and Xieyang Liu and Huayi Zeng and Jia Deng},\n    title = {Learning to Detect Human-Object Interactions},\n    booktitle = {Proceedings of the IEEE Winter Conference on Applications of Computer Vision},\n    year = {2018},\n  }    \n      ",previewImgLink:a,projectPageLink:"http://www-personal.umich.edu/~ywchao/hico/",codebaseLink:"https://github.com/ywchao/ho-rcnn",doi:"http://doi.org/10.1109/WACV.2018.00048",ieeexplore:"https://ieeexplore.ieee.org/document/8354152"},{title:"Supporting Knowledge Acceleration for Programming from a Sensemaking Perspective",type:"workshop",conference:"CHI",conferenceFullName:"Sensemaking Workshop @ The ACM Conference on Human Factors in Computing Systems (CHI)",conferenceTag:"CHI 2018",year:2018,month:4,authors:[{name:"Michael Xieyang Liu",bold:!0},{name:"Shaun Burley",bold:!1},{name:"Emily Deng",bold:!1},{name:"Angelina Zhou",bold:!1},{name:"Aniket Kittur",bold:!1},{name:"Brad A. Myers",bold:!1}],abstract:"Programmers spend a signiﬁcant proportion of their time searching for and making sense of complex information. However, they often lack effective tools to help them make sense of the information, turn it into knowledge, or share it with their respective communities. In this position paper, we aim to help programmers collect, navigate, and organize knowledge to meet their goals while capturing this knowledge and making it useful for later programmers with similar needs. We describe barriers and challenges to creating this sustainable cycle, and we explore the design space and opportunities for effective tools and systems.",codename:"kap-sensemaking-workshop",previewImgLink:"data:image/png;base64,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"},{title:"UNAKITE: Support Developers for Capturing and Persisting Design Rationales When Solving Problems Using Web Resources",type:"workshop",conference:"VL/HCC",conferenceFullName:"DTSHPS'18 Workshop on Designing Technologies to Support Human Problem Solving",conferenceTag:"VL/HCC 2018",year:2018,month:10,authors:[{name:"Michael Xieyang Liu",bold:!0},{name:"Nathan Hahn",bold:!1},{name:"Angelina Zhou",bold:!1},{name:"Shaun Burley",bold:!1},{name:"Emily Deng",bold:!1},{name:"Aniket Kittur",bold:!1},{name:"Brad A. Myers",bold:!1}],abstract:"UNAKITE is a new system that supports developers in collecting, organizing, consuming, and persisting design rationales while solving problems using web resources. Understanding design rationale has widely been recognized as signiﬁcant for the success of a software engineering project. However, it is currently both time and labor intensive for little immediate payoff for a developer to generate and embed a useful design rationale in their code. Under this cost structure, there is very little effective tool support to help developers keep track of design rationales. UNAKITE addresses this challenge for some design decisions by changing the cost structure: developers are incentivized to make decisions using UNAKITE's collecting and organizing mechanisms as it makes tracking and deciding between alternatives easier than before; the structure thus generated is automatically embedded in the code as the design rationale when the developer copies sample code into their existing code. In a preliminary usability study developers found UNAKITE to be usable for capturing design rationales and effective for interpreting the rationale of others.",codename:"unakite-vlhcc-workshop",previewImgLink:o,shouldShowLocalPaperLink:!0},{title:"An Exploratory Study of Web Foraging to Understand and Support Programming Decisions",type:"poster",conference:"VL/HCC",conferenceFullName:"IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)",conferenceTag:"VL/HCC 2018",year:2018,month:10,authors:[{name:"Jane Hsieh",bold:!1},{name:"Michael Xieyang Liu",bold:!0},{name:"Brad A. Myers",bold:!1},{name:"Aniket Kittur",bold:!1}],abstract:"Programmers consistently engage in cognitively demanding tasks such as sensemaking and decision-making. During the information-foraging process, programmers are growing more reliant on resources available online since they contain masses of crowdsourced information and are easier to navigate. Content available in questions and answers on Stack Overflow presents a unique platform for studying the types of problems encountered in programming and possible solutions. In addition to classifying these questions, we introduce possible visual representations for organizing the gathered information and propose that such models may help reduce the cost of navigating, understanding and choosing solution alternatives.",codename:"stackoverflow-vlhcc-workshop",previewImgLink:i,shouldShowLocalPaperLink:!0,doi:"https://doi.org/10.1109/VLHCC.2018.8506517",ieeexplore:"https://ieeexplore.ieee.org/document/8506517"},{title:"Popup: Reconstructing 3D Video Using Particle Filtering to Aggregate Crowd Responses",type:"conference",conference:"IUI",conferenceFullName:"ACM International Conference on Intelligent User Interfaces (IUI)",conferenceTag:"IUI 2019",year:2019,month:3,authors:[{name:"Jean Y. Song",bold:!1},{name:"Stephan J. Lemmer",bold:!1},{name:"Michael Xieyang Liu",bold:!0},{name:"Shiyan Yan",bold:!1},{name:"Juho Kim",bold:!1},{name:"Jason J. Corso",bold:!1},{name:"Walter S. Lasecki",bold:!1}],abstract:"Collecting a sufficient amount of 3D training data for autonomous vehicles to handle rare, but critical, traffic events (e.g., collisions) may take decades of deployment. Abundant video data of such events from municipal traffic cameras and video sharing sites (e.g., YouTube) could provide a potential alternative, but generating realistic training data in the form of 3D video reconstructions is a challenging task beyond the current capabilities of computer vision. Crowdsourcing manual annotations of necessary information has the potential to bridge this gap, but the level of accuracy required to attain usable reconstructions makes this a nearly impossible task for non-experts. In this paper, we propose a novel crowd-machine hybrid method that combines annotations from multiple contents by adopting particle filtering as an aggregation technique. Our approach is capable of leveraging temporal dependencies between video frames, enabling more aggressive filtering thresholds for annotations that can help improve the aggregation quality. The proposed method results in a 33% reduction in the relative error of position estimation compared to a state-of-the-art baseline. Moreover, our method enables skip-based (self-filtering) annotation that reduces the total annotation time for hard-to-annotate frames by 16%. Our approach provides a generalizable means of aggregating more accurate crowd responses even in settings where annotation is especially challenging or error-prone.",codename:"av_anno",bibtex:"",previewImgLink:r,shouldShowLocalPaperLink:!0,doi:"https://doi.org/10.1145/3301275.3302305",acmdl:"https://dl.acm.org/citation.cfm?id=3302305",conferenceTalkVideo:"https://youtu.be/hn0r9Eb9_rQ"},{title:"Unakite: Scaffolding Developers’ Decision-Making Using the Web",type:"conference",conference:"UIST",conferenceFullName:"ACM Symposium on User Interface Software and Technology (UIST)",conferenceTag:"UIST 2019",year:2019,month:10,authors:[{name:"Michael Xieyang Liu",bold:!0},{name:"Jane Hsieh",bold:!1},{name:"Nathan Hahn",bold:!1},{name:"Angelina Zhou",bold:!1},{name:"Emily Deng",bold:!1},{name:"Shaun Burley",bold:!1},{name:"Cynthia Taylor",bold:!1},{name:"Aniket Kittur",bold:!1},{name:"Brad A. Myers",bold:!1}],abstract:"Developers spend a significant portion of their time searching for solutions and methods online. While numerous tools have been developed to support this exploratory process, in many cases the answers to developers' questions involve trade-offs among multiple valid options and not just a single solution. Through interviews, we discovered that developers express a desire for help with decision-making and understanding trade-offs. Through an analysis of Stack Overflow posts, we observed that many answers describe such trade-offs. These findings suggest that tools designed to help a developer capture information and make decisions about trade-offs can provide crucial benefits for both the developers and others who want to understand their design rationale. In this work, we probe this hypothesis with a prototype system named Unakite that collects, organizes, and keeps track of information about trade-offs and builds a comparison table, which can be saved as a design rationale for later use. Our evaluation results show that Unakite reduces the cost of capturing tradeoff-related information by 45%, and that the resulting comparison table speeds up a subsequent developer's ability to understand the trade-offs by about a factor of three.",codename:"unakite-uist-2019",bibtex:"",previewImgLink:s,shouldShowLocalPaperLink:!0,doi:"http://dx.doi.org/10.1145/3332165.3347908",acmdl:"http://dx.doi.org/10.1145/3332165.3347908",acmdl_available:!0,award:{honorableMention:!0},conferenceTalkVideo:"https://youtu.be/UMQ-kWgmbQ4"},{title:"Tabs.do: Task-Centric Browser Tab Management",type:"conference",conference:"UIST",conferenceFullName:"ACM Symposium on User Interface Software and Technology (UIST)",conferenceTag:"UIST 2021",year:2021,month:10,authors:[{name:"Joseph Chee Chang",bold:!1},{name:"Yongsung Kim",bold:!1},{name:"Victor Miller",bold:!1},{name:"Michael Xieyang Liu",bold:!0},{name:"Brad A. Myers",bold:!1},{name:"Aniket Kittur",bold:!1}],abstract:"Despite the increasing complexity and scale of people's online activities, browser interfaces have stayed largely the same since tabs were introduced in major browsers nearly 20 years ago. The gap between simple tab-based browser interfaces and the complexity of users' tasks can lead to serious adverse effects – commonly referred to as \"tab overload.\" This paper introduces a Chrome extension called Tabs.do, which explores bringing a task-centric approach to the browser, helping users to group their tabs into tasks and then organize, prioritize, and switch between those tasks fluidly. To lower the cost of importing, Tabs.do uses machine learning to make intelligent suggestions for grouping users' open tabs into task bundles by exploiting behavioral and semantic features. We conducted a field deployment study where participants used Tabs.do with their real-life tasks in the wild, and showed that Tabs.do can decrease tab clutter, enabled users to create rich task structures with lightweight interactions, and allowed participants to context-switch among tasks more efficiently.",codename:"tabsdo-uist-2021",bibtex:"",previewImgLink:l,shouldShowLocalPaperLink:!0,doi:"https://doi.org/10.1145/3472749.3474777",acmdl:"https://doi.org/10.1145/3472749.3474777",acmdl_available:!0,award:{honorableMention:!1}},{title:"To Reuse or Not To Reuse? A Framework and System for Evaluating Summarized Knowledge",type:"conference",conference:"CSCW",conferenceFullName:"ACM Conference on Computer Supported Cooperative Work and Social Computing (CSCW)",conferenceTag:"CSCW 2021",year:2021,month:10,authors:[{name:"Michael Xieyang Liu",bold:!0},{name:"Aniket Kittur",bold:!1},{name:"Brad A. Myers",bold:!1}],abstract:"As the amount of information online continues to grow, a correspondingly important opportunity is for individuals to reuse knowledge which has been summarized by others rather than starting from scratch. However, appropriate reuse requires judging the relevance, trustworthiness, and thoroughness of others' knowledge in relation to an individual's goals and context. In this work, we explore augmenting judgements of the appropriateness of reusing knowledge in the domain of programming, specifically of reusing artifacts that result from other developers' searching and decision making. Through an analysis of prior research on sensemaking and trust, along with new interviews with developers, we synthesized a framework for reuse judgements. The interviews also validated that developers express a desire for help with judging whether to reuse an existing decision. From this framework, we developed a set of techniques for capturing the initial decision maker's behavior and visualizing signals calculated based on the behavior, to facilitate subsequent consumers' reuse decisions, instantiated in a prototype system called Strata. Results of a user study suggest that the system significantly improves the accuracy, depth, and speed of reusing decisions. These results have implications for systems involving user-generated content in which other users need to evaluate the relevance and trustworthiness of that content.",codename:"strata-cscw-2021",bibtex:"",previewImgLink:c,shouldShowLocalPaperLink:!0,doi:"https://doi.org/10.1145/3449240",acmdl:"https://doi.org/10.1145/3449240",arxiv:"https://arxiv.org/abs/2102.06231",cmuSCSMedia:"https://www.cs.cmu.edu/news/2021/reuse-content-tool",acmdl_available:!0,award:{bestPaper:!0},conferenceTalkVideo:"https://youtu.be/NuL-jtf710E"},{title:"Understanding How Programmers Can Use Annotations on Documentation",type:"conference",conference:"CHI",conferenceFullName:"ACM CHI Conference on Human Factors in Computing Systems (CHI)",conferenceTag:"CHI 2022",year:2022,month:4,authors:[{name:"Amber Horvath",bold:!1},{name:"Michael Xieyang Liu",bold:!0},{name:"River Hendriksen",bold:!1},{name:"Connor Shannon",bold:!1},{name:"Emma Paterson",bold:!1},{name:"Kazi Jawad",bold:!1},{name:"Andrew Macvean",bold:!1},{name:"Brad A. Myers",bold:!1}],abstract:"Coming soon...",codename:"adamite-chi-2022",bibtex:"",previewImgLink:h,shouldShowLocalPaperLink:!1,acmdl_available:!1},{title:"Crystalline: Lowering the Cost for Developers to Collect and Organize Information for Decision Making",type:"conference",conference:"CHI",conferenceFullName:"ACM CHI Conference on Human Factors in Computing Systems (CHI)",conferenceTag:"CHI 2022",year:2022,month:4,authors:[{name:"Michael Xieyang Liu",bold:!0},{name:"Aniket Kittur",bold:!1},{name:"Brad A. Myers",bold:!1}],abstract:"Coming soon...",codename:"crystalline-chi-2022",bibtex:"",previewImgLink:d,shouldShowLocalPaperLink:!1,acmdl_available:!1}]}}}]);
//# sourceMappingURL=c7fb939e48a5a444c57c9e9c7ca61fcfe6ffbd1c-c4cedac45fe7da2da343.js.map